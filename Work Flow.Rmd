---
title: "Seedling Density Work Flow"
output: html_document
date: "2025-11-06"
---
# Climatic drivers of Oregon Seedling Density 

**By Bryce DiNardo**

## Literature review (~5 paragraphs)

### Paragraph 1 — Problem & significance (big‑picture reviews)
…

### Paragraph 2–3 — Past work & data landscape (who/where/how; gaps)
…

### Paragraph 4 — Purpose & why now
…

### Paragraph 5 — Hypotheses (directional) & brief rationale
- H1: … (I predict … because …)
- H2: …

## Dataset identification
- Dataset A (URL/DOI): collector, methods, columns/units …
- OBA → transformed to … (plan and rationale) …

## Workflow plan (prose)
1) Cleaning & validation: …  
2) Aggregations/derivations: …  
3) Functions/loops (inputs → outputs): …  
4) Statistical test + programmatic implementation: …  
5) Planned visualizations/tables: …  
6) Risks & mitigations: …

In pros, please describe the workflow you will use tidy your raw data, manipulate and summarize it in relevant ways, test you hypothesis, and visualize it.The goal here is to develop a logic to your workflow before you code.

Include any needed cleaning steps (e.g., “remove non-species such as ‘fly’ from the species column”)
Include any aggregation steps (e.g., “count the number of entries by region and year to calculate species richness”).
Include descriptions of any functions/for loops you will write.
Include a description the the statistical test you will use, and how you will apply it programatically (i.e., I will simulate the null hypothesis by shuffling the labels…“)

**Cleaning and processing FIA data**
Import all OR FIA data using rFIA 
Extract Seedling tree per arch (TPA) for each year of data wanted. 
Do this by using rFIA seedling function, I want to seedling density groupby plot, returnSPatial == TRUE, and bySpecies.
This will give me the TPA for each species in each plot and have then in an Oregon polygon. Not sure yet if I need to provide a shp file for that yet, but easy enough if so.

Now I have a bunch of seedling densities, sorted by plot and species
*Next lets filter to clean some data*
Filter for only forest plots (PLOT_STATUS_CD == 1)
Remove TPA NAs and 0 values or "unknown" 
Remove sites with missing Lat or Long values
Filter for year wanted(2013 - 2022 one complete inventory cycle of most recent)

Great now we have cleaned seedling density for all species that occur in each plot throughout the state in that given year this is our *responds variable*

**Climate Data Acquisition, Cleaning and Calculation**

Climate data will be download from GridMAT using using the download_data function from the amadeus package.

Each download will be for a specific year and climatic variable. The three main once I will get is Minimum Near-Surface Air Temperature, Maximum Near-Surface Air Temperature, and precipitation. From the function will be a downloaded .nc file, ready to be processed. 
list.files() will be used to make sure download succeeded and to check the correct directory name to be used in the next step. 

Once acquire I will have a function that takes which ever variable and does the following.

Inputs: year, climate variable, and directory
Output: yearly mean raster data with the Oregon vector. Then there is an if statement, where if the variable is either Minimum Near-Surface Air Temperature or Maximum Near-Surface Air Temperature. Or annual precip

Processes the covariates using the process_covariates function, then get a shp file for Oregon using tirgirs library, re-object the Oregon shp to the same crs as the rasters that come from process_covariates. Then crop and mask the raster data with the Oregon vector. Then there is an if statement, where if the variable is either Minimum Near-Surface Air Temperature or Maximum Near-Surface Air Temperature, then terra::mean is used to calculate the mean max and min yearly temperature, outputting a single raster, with the units in C, and then saving it as a .TIF. If the variable is precipitation, then sum is used to calculate annual rainfall, single raster download and saved as .TIF

I will also have a temperature mean function, that simply takes the outputs from the max and min temperature variables and computes a yearly average temperature.

This will be done for all years of interest, 2022-2014 (matches the survey time frame of the last fully completed FIA survey)

To validate the successful completion of data process, I will used: class(result), nlyr(result)
terra::plot(result)
summary(values(result))
To make sure the data type is as expected, is the expected number of raster layers, it plots as expect, and values are within a reasonable range. 

**Further data wrangling, combining climate and FIA**



**Statistical tests**



**Visualizations**



**Risks**





















##Work Flow
#Part 1: FIA data aquistion and processing
**Load packages**
install.packages("rFIA")
library("rFIA")
library("dplyr")
library("tidyr")

**Data aquistion**
Get all FIA data for Oregon by using rFIA
```{r}
options(timeout = 600) #Need to increase download time since file is so large
#Grab the data
OR <- getFIA(states = 'OR', dir = "C:/Users/dinardo/OneDrive - University Of Oregon/FIA", load = FALSE) #Install the data
OR <- readFIA(dir = "C:/Users/dinardo/OneDrive - University Of Oregon/FIA",
              states = 'OR',
              nCores = 1,
              inMemory = TRUE)
```

